{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Geospatial Data\n",
    "\n",
    "### CHAFIK Hala  | EL OMARI Chaimae  |  DEMRI Lina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read GeoJson files\n",
    "\n",
    "train_df = gpd.read_file('train.geojson', index_col=0)\n",
    "test_df = gpd.read_file('test.geojson', index_col=0)\n",
    "\n",
    "##Convert GeoJson files into CSV files\n",
    "\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train_df=pd.read_csv('train.csv')\n",
    "\n",
    "main_test_df=pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['urban_type', 'geography_type', 'img_red_mean_date1',\n",
       "       'img_green_mean_date1', 'img_blue_mean_date1', 'img_red_std_date1',\n",
       "       'img_green_std_date1', 'img_blue_std_date1', 'img_red_mean_date2',\n",
       "       'img_green_mean_date2', 'img_blue_mean_date2', 'img_red_std_date2',\n",
       "       'img_green_std_date2', 'img_blue_std_date2', 'img_red_mean_date3',\n",
       "       'img_green_mean_date3', 'img_blue_mean_date3', 'img_red_std_date3',\n",
       "       'img_green_std_date3', 'img_blue_std_date3', 'img_red_mean_date4',\n",
       "       'img_green_mean_date4', 'img_blue_mean_date4', 'img_red_std_date4',\n",
       "       'img_green_std_date4', 'img_blue_std_date4', 'img_red_mean_date5',\n",
       "       'img_green_mean_date5', 'img_blue_mean_date5', 'img_red_std_date5',\n",
       "       'img_green_std_date5', 'img_blue_std_date5', 'date0',\n",
       "       'change_status_date0', 'date1', 'change_status_date1', 'date2',\n",
       "       'change_status_date2', 'date3', 'change_status_date3', 'date4',\n",
       "       'change_status_date4', 'index', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=main_train_df.copy()\n",
    "test_df=main_test_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urban_type</th>\n",
       "      <th>geography_type</th>\n",
       "      <th>change_type</th>\n",
       "      <th>img_red_mean_date1</th>\n",
       "      <th>img_green_mean_date1</th>\n",
       "      <th>img_blue_mean_date1</th>\n",
       "      <th>img_red_std_date1</th>\n",
       "      <th>img_green_std_date1</th>\n",
       "      <th>img_blue_std_date1</th>\n",
       "      <th>img_red_mean_date2</th>\n",
       "      <th>...</th>\n",
       "      <th>date1</th>\n",
       "      <th>change_status_date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>change_status_date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>change_status_date3</th>\n",
       "      <th>date4</th>\n",
       "      <th>change_status_date4</th>\n",
       "      <th>index</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparse Urban</td>\n",
       "      <td>Dense Forest,Grass Land</td>\n",
       "      <td>Road</td>\n",
       "      <td>93.371775</td>\n",
       "      <td>107.291113</td>\n",
       "      <td>89.827379</td>\n",
       "      <td>29.81204</td>\n",
       "      <td>28.328368</td>\n",
       "      <td>25.324294</td>\n",
       "      <td>125.773062</td>\n",
       "      <td>...</td>\n",
       "      <td>09-12-2013</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>10-09-2016</td>\n",
       "      <td>Construction Started</td>\n",
       "      <td>22-07-2019</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>24-07-2017</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((112.16774086470313 32.0219772550438,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse Urban</td>\n",
       "      <td>Dense Forest,Grass Land</td>\n",
       "      <td>Road</td>\n",
       "      <td>96.071674</td>\n",
       "      <td>107.061702</td>\n",
       "      <td>90.755556</td>\n",
       "      <td>24.89624</td>\n",
       "      <td>22.275180</td>\n",
       "      <td>22.080686</td>\n",
       "      <td>133.097679</td>\n",
       "      <td>...</td>\n",
       "      <td>09-12-2013</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>10-09-2016</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>22-07-2019</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>24-07-2017</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((112.16848748857684 32.02047741874698...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     urban_type           geography_type change_type  img_red_mean_date1  \\\n",
       "0  Sparse Urban  Dense Forest,Grass Land        Road           93.371775   \n",
       "1  Sparse Urban  Dense Forest,Grass Land        Road           96.071674   \n",
       "\n",
       "   img_green_mean_date1  img_blue_mean_date1  img_red_std_date1  \\\n",
       "0            107.291113            89.827379           29.81204   \n",
       "1            107.061702            90.755556           24.89624   \n",
       "\n",
       "   img_green_std_date1  img_blue_std_date1  img_red_mean_date2  ...  \\\n",
       "0            28.328368           25.324294          125.773062  ...   \n",
       "1            22.275180           22.080686          133.097679  ...   \n",
       "\n",
       "        date1  change_status_date1       date2   change_status_date2  \\\n",
       "0  09-12-2013            Greenland  10-09-2016  Construction Started   \n",
       "1  09-12-2013            Greenland  10-09-2016          Land Cleared   \n",
       "\n",
       "        date3  change_status_date3       date4  change_status_date4  index  \\\n",
       "0  22-07-2019    Construction Done  24-07-2017  Construction Midway      0   \n",
       "1  22-07-2019    Construction Done  24-07-2017  Construction Midway      1   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((112.16774086470313 32.0219772550438,...  \n",
       "1  POLYGON ((112.16848748857684 32.02047741874698...  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling urban and geography type through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_type</th>\n",
       "      <th>img_red_mean_date1</th>\n",
       "      <th>img_green_mean_date1</th>\n",
       "      <th>img_blue_mean_date1</th>\n",
       "      <th>img_red_std_date1</th>\n",
       "      <th>img_green_std_date1</th>\n",
       "      <th>img_blue_std_date1</th>\n",
       "      <th>img_red_mean_date2</th>\n",
       "      <th>img_green_mean_date2</th>\n",
       "      <th>img_blue_mean_date2</th>\n",
       "      <th>...</th>\n",
       "      <th>geography_type_Hills</th>\n",
       "      <th>geography_type_Lakes</th>\n",
       "      <th>geography_type_River</th>\n",
       "      <th>geography_type_Snow</th>\n",
       "      <th>geography_type_Sparse Forest</th>\n",
       "      <th>urban_type_Dense Urban</th>\n",
       "      <th>urban_type_Industrial</th>\n",
       "      <th>urban_type_Rural</th>\n",
       "      <th>urban_type_Sparse Urban</th>\n",
       "      <th>urban_type_Urban Slum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Road</td>\n",
       "      <td>93.371775</td>\n",
       "      <td>107.291113</td>\n",
       "      <td>89.827379</td>\n",
       "      <td>29.812040</td>\n",
       "      <td>28.328368</td>\n",
       "      <td>25.324294</td>\n",
       "      <td>125.773062</td>\n",
       "      <td>139.833243</td>\n",
       "      <td>134.900701</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Road</td>\n",
       "      <td>96.071674</td>\n",
       "      <td>107.061702</td>\n",
       "      <td>90.755556</td>\n",
       "      <td>24.896240</td>\n",
       "      <td>22.275180</td>\n",
       "      <td>22.080686</td>\n",
       "      <td>133.097679</td>\n",
       "      <td>145.385190</td>\n",
       "      <td>137.092518</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Road</td>\n",
       "      <td>101.212148</td>\n",
       "      <td>113.462178</td>\n",
       "      <td>95.670574</td>\n",
       "      <td>24.179684</td>\n",
       "      <td>21.873401</td>\n",
       "      <td>21.285197</td>\n",
       "      <td>120.713490</td>\n",
       "      <td>131.633447</td>\n",
       "      <td>124.436492</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Road</td>\n",
       "      <td>94.463311</td>\n",
       "      <td>99.995531</td>\n",
       "      <td>84.470046</td>\n",
       "      <td>26.869852</td>\n",
       "      <td>23.767679</td>\n",
       "      <td>19.351983</td>\n",
       "      <td>114.819776</td>\n",
       "      <td>127.827828</td>\n",
       "      <td>120.435373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Demolition</td>\n",
       "      <td>151.883646</td>\n",
       "      <td>191.710197</td>\n",
       "      <td>211.569244</td>\n",
       "      <td>52.465332</td>\n",
       "      <td>59.441844</td>\n",
       "      <td>52.304349</td>\n",
       "      <td>141.514462</td>\n",
       "      <td>171.079581</td>\n",
       "      <td>181.960612</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  change_type  img_red_mean_date1  img_green_mean_date1  img_blue_mean_date1  \\\n",
       "0        Road           93.371775            107.291113            89.827379   \n",
       "1        Road           96.071674            107.061702            90.755556   \n",
       "2        Road          101.212148            113.462178            95.670574   \n",
       "3        Road           94.463311             99.995531            84.470046   \n",
       "4  Demolition          151.883646            191.710197           211.569244   \n",
       "\n",
       "   img_red_std_date1  img_green_std_date1  img_blue_std_date1  \\\n",
       "0          29.812040            28.328368           25.324294   \n",
       "1          24.896240            22.275180           22.080686   \n",
       "2          24.179684            21.873401           21.285197   \n",
       "3          26.869852            23.767679           19.351983   \n",
       "4          52.465332            59.441844           52.304349   \n",
       "\n",
       "   img_red_mean_date2  img_green_mean_date2  img_blue_mean_date2  ...  \\\n",
       "0          125.773062            139.833243           134.900701  ...   \n",
       "1          133.097679            145.385190           137.092518  ...   \n",
       "2          120.713490            131.633447           124.436492  ...   \n",
       "3          114.819776            127.827828           120.435373  ...   \n",
       "4          141.514462            171.079581           181.960612  ...   \n",
       "\n",
       "   geography_type_Hills  geography_type_Lakes  geography_type_River  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   geography_type_Snow  geography_type_Sparse Forest  urban_type_Dense Urban  \\\n",
       "0                    0                             0                       0   \n",
       "1                    0                             0                       0   \n",
       "2                    0                             0                       0   \n",
       "3                    0                             0                       0   \n",
       "4                    0                             1                       1   \n",
       "\n",
       "   urban_type_Industrial  urban_type_Rural  urban_type_Sparse Urban  \\\n",
       "0                      0                 0                        1   \n",
       "1                      0                 0                        1   \n",
       "2                      0                 0                        1   \n",
       "3                      0                 1                        0   \n",
       "4                      0                 0                        0   \n",
       "\n",
       "   urban_type_Urban Slum  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_geography_type = train_df['geography_type'].str.split(',', expand=True)  #seeing that there exists many geography type for the same feature,\n",
    "one_hot_encoded_geo = pd.get_dummies(split_geography_type.stack(), prefix='geography_type',dtype=int).groupby(level=0).max() # for the one hot encoding to work, we must split the data on ',' character.\n",
    "\n",
    "one_hot_encoded_geo=one_hot_encoded_geo.drop(columns=['geography_type_A'])\n",
    "one_hot_encoded_geo=one_hot_encoded_geo.drop(columns=['geography_type_N'])\n",
    "\n",
    "\n",
    "train_df=pd.concat([train_df,one_hot_encoded_geo],axis=1)\n",
    "\n",
    "split_urban_type=train_df['urban_type'].str.split(',',expand=True)\n",
    "one_hot_encoded_urb= pd.get_dummies(split_urban_type.stack(), prefix='urban_type',dtype=int).groupby(level=0).max()\n",
    "\n",
    "one_hot_encoded_urb=one_hot_encoded_urb.drop(columns=['urban_type_A'])\n",
    "one_hot_encoded_urb=one_hot_encoded_urb.drop(columns=['urban_type_N'])\n",
    "\n",
    "train_df=pd.concat([train_df,one_hot_encoded_urb],axis=1)\n",
    "\n",
    "train_df.drop('geography_type',axis=1,inplace=True)\n",
    "train_df.drop('urban_type',axis=1,inplace=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_geography_type = test_df['geography_type'].str.split(',', expand=True)\n",
    "one_hot_encoded_geo = pd.get_dummies(split_geography_type.stack(), prefix='geography_type',dtype=int).groupby(level=0).max()\n",
    "\n",
    "if 'geography_type_A' in one_hot_encoded_geo.columns:\n",
    "    one_hot_encoded_geo=one_hot_encoded_geo.drop(columns=['geography_type_A'])\n",
    "if 'geography_type_N' in one_hot_encoded_geo.columns:  \n",
    "    one_hot_encoded_geo=one_hot_encoded_geo.drop(columns=['geography_type_N'])\n",
    "\n",
    "\n",
    "test_df=pd.concat([test_df,one_hot_encoded_geo],axis=1)\n",
    "\n",
    "split_urban_type=test_df['urban_type'].str.split(',',expand=True)\n",
    "one_hot_encoded_urb= pd.get_dummies(split_urban_type.stack(), prefix='urban_type',dtype=int).groupby(level=0).max()\n",
    "if 'urban_type_A' in one_hot_encoded_urb.columns:\n",
    "    one_hot_encoded_urb=one_hot_encoded_urb.drop(columns=['urban_type_A'])\n",
    "if 'urban_type_N' in one_hot_encoded_urb.columns:\n",
    "    one_hot_encoded_urb=one_hot_encoded_urb.drop(columns=['urban_type_N'])\n",
    "\n",
    "test_df=pd.concat([test_df,one_hot_encoded_urb],axis=1)\n",
    "\n",
    "test_df.drop('geography_type',axis=1,inplace=True)\n",
    "test_df.drop('urban_type',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ordering the dates\n",
    "\n",
    "First, we start by creating a data frame contaning the date related columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date0</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date4</th>\n",
       "      <th>change_status_date0</th>\n",
       "      <th>change_status_date1</th>\n",
       "      <th>change_status_date2</th>\n",
       "      <th>change_status_date3</th>\n",
       "      <th>change_status_date4</th>\n",
       "      <th>...</th>\n",
       "      <th>img_blue_std_date2</th>\n",
       "      <th>img_red_std_date3</th>\n",
       "      <th>img_green_std_date3</th>\n",
       "      <th>img_blue_std_date3</th>\n",
       "      <th>img_red_std_date4</th>\n",
       "      <th>img_green_std_date4</th>\n",
       "      <th>img_blue_std_date4</th>\n",
       "      <th>img_red_std_date5</th>\n",
       "      <th>img_green_std_date5</th>\n",
       "      <th>img_blue_std_date5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>2016-09-10</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Started</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>...</td>\n",
       "      <td>25.008032</td>\n",
       "      <td>55.745311</td>\n",
       "      <td>47.576383</td>\n",
       "      <td>42.723218</td>\n",
       "      <td>39.819949</td>\n",
       "      <td>30.864230</td>\n",
       "      <td>28.189604</td>\n",
       "      <td>33.813160</td>\n",
       "      <td>33.064014</td>\n",
       "      <td>34.818012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>2016-09-10</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>...</td>\n",
       "      <td>20.271657</td>\n",
       "      <td>42.130924</td>\n",
       "      <td>38.138137</td>\n",
       "      <td>35.142246</td>\n",
       "      <td>37.129531</td>\n",
       "      <td>28.089549</td>\n",
       "      <td>25.901238</td>\n",
       "      <td>30.670052</td>\n",
       "      <td>33.258905</td>\n",
       "      <td>36.139281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>2016-09-10</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>...</td>\n",
       "      <td>22.505835</td>\n",
       "      <td>58.434034</td>\n",
       "      <td>48.106798</td>\n",
       "      <td>43.902810</td>\n",
       "      <td>42.510625</td>\n",
       "      <td>33.189102</td>\n",
       "      <td>30.522871</td>\n",
       "      <td>34.436045</td>\n",
       "      <td>33.546000</td>\n",
       "      <td>35.545531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>2016-09-10</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Started</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>...</td>\n",
       "      <td>23.901639</td>\n",
       "      <td>51.046935</td>\n",
       "      <td>44.444291</td>\n",
       "      <td>40.558345</td>\n",
       "      <td>39.111827</td>\n",
       "      <td>30.762028</td>\n",
       "      <td>28.337671</td>\n",
       "      <td>31.285068</td>\n",
       "      <td>32.613142</td>\n",
       "      <td>36.080342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>2016-09-10</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Prior Construction</td>\n",
       "      <td>Prior Construction</td>\n",
       "      <td>Prior Construction</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Prior Construction</td>\n",
       "      <td>...</td>\n",
       "      <td>41.600845</td>\n",
       "      <td>32.054249</td>\n",
       "      <td>40.833531</td>\n",
       "      <td>48.325621</td>\n",
       "      <td>27.578335</td>\n",
       "      <td>28.158172</td>\n",
       "      <td>27.306766</td>\n",
       "      <td>40.627077</td>\n",
       "      <td>37.989182</td>\n",
       "      <td>37.177376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296141</th>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>...</td>\n",
       "      <td>18.072115</td>\n",
       "      <td>22.149322</td>\n",
       "      <td>21.775425</td>\n",
       "      <td>21.220923</td>\n",
       "      <td>31.735119</td>\n",
       "      <td>27.878950</td>\n",
       "      <td>22.753705</td>\n",
       "      <td>39.430303</td>\n",
       "      <td>31.233005</td>\n",
       "      <td>32.695174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296142</th>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>...</td>\n",
       "      <td>21.063869</td>\n",
       "      <td>36.244103</td>\n",
       "      <td>44.609578</td>\n",
       "      <td>49.829084</td>\n",
       "      <td>52.820758</td>\n",
       "      <td>56.492413</td>\n",
       "      <td>58.892309</td>\n",
       "      <td>57.208272</td>\n",
       "      <td>55.111372</td>\n",
       "      <td>57.120977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296143</th>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>...</td>\n",
       "      <td>11.146906</td>\n",
       "      <td>16.453913</td>\n",
       "      <td>13.275921</td>\n",
       "      <td>11.146906</td>\n",
       "      <td>13.538151</td>\n",
       "      <td>11.347441</td>\n",
       "      <td>11.297618</td>\n",
       "      <td>27.654293</td>\n",
       "      <td>26.528809</td>\n",
       "      <td>25.034740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296144</th>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>Construction Midway</td>\n",
       "      <td>Land Cleared</td>\n",
       "      <td>...</td>\n",
       "      <td>22.268071</td>\n",
       "      <td>29.719189</td>\n",
       "      <td>26.584532</td>\n",
       "      <td>22.268071</td>\n",
       "      <td>23.167710</td>\n",
       "      <td>22.728428</td>\n",
       "      <td>22.132447</td>\n",
       "      <td>58.078044</td>\n",
       "      <td>54.960466</td>\n",
       "      <td>53.635703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296145</th>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>Construction Done</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>...</td>\n",
       "      <td>22.657286</td>\n",
       "      <td>29.863493</td>\n",
       "      <td>26.546770</td>\n",
       "      <td>22.657286</td>\n",
       "      <td>19.702818</td>\n",
       "      <td>18.111208</td>\n",
       "      <td>17.132445</td>\n",
       "      <td>47.110624</td>\n",
       "      <td>42.584237</td>\n",
       "      <td>46.635505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296146 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date0      date1      date2      date3      date4  \\\n",
       "0      2018-08-01 2013-12-09 2016-09-10 2019-07-22 2017-07-24   \n",
       "1      2018-08-01 2013-12-09 2016-09-10 2019-07-22 2017-07-24   \n",
       "2      2018-08-01 2013-12-09 2016-09-10 2019-07-22 2017-07-24   \n",
       "3      2018-08-01 2013-12-09 2016-09-10 2019-07-22 2017-07-24   \n",
       "4      2018-08-01 2013-12-09 2016-09-10 2019-07-22 2017-07-24   \n",
       "...           ...        ...        ...        ...        ...   \n",
       "296141 2014-11-19 2017-02-25 2014-01-27 2018-03-28 2015-12-28   \n",
       "296142 2014-11-19 2017-02-25 2014-01-27 2018-03-28 2015-12-28   \n",
       "296143 2014-11-19 2017-02-25 2014-01-27 2018-03-28 2015-12-28   \n",
       "296144 2014-11-19 2017-02-25 2014-01-27 2018-03-28 2015-12-28   \n",
       "296145 2014-11-19 2017-02-25 2014-01-27 2018-03-28 2015-12-28   \n",
       "\n",
       "        change_status_date0 change_status_date1   change_status_date2  \\\n",
       "0         Construction Done           Greenland  Construction Started   \n",
       "1       Construction Midway           Greenland          Land Cleared   \n",
       "2         Construction Done           Greenland          Land Cleared   \n",
       "3       Construction Midway           Greenland  Construction Started   \n",
       "4        Prior Construction  Prior Construction    Prior Construction   \n",
       "...                     ...                 ...                   ...   \n",
       "296141            Greenland   Construction Done          Land Cleared   \n",
       "296142            Greenland   Construction Done             Greenland   \n",
       "296143            Greenland   Construction Done             Greenland   \n",
       "296144         Land Cleared        Land Cleared          Land Cleared   \n",
       "296145            Greenland           Greenland             Greenland   \n",
       "\n",
       "        change_status_date3  change_status_date4  ...  img_blue_std_date2  \\\n",
       "0         Construction Done  Construction Midway  ...           25.008032   \n",
       "1         Construction Done  Construction Midway  ...           20.271657   \n",
       "2         Construction Done         Land Cleared  ...           22.505835   \n",
       "3         Construction Done  Construction Midway  ...           23.901639   \n",
       "4              Land Cleared   Prior Construction  ...           41.600845   \n",
       "...                     ...                  ...  ...                 ...   \n",
       "296141    Construction Done         Land Cleared  ...           18.072115   \n",
       "296142    Construction Done         Land Cleared  ...           21.063869   \n",
       "296143    Construction Done            Greenland  ...           11.146906   \n",
       "296144  Construction Midway         Land Cleared  ...           22.268071   \n",
       "296145    Construction Done            Greenland  ...           22.657286   \n",
       "\n",
       "        img_red_std_date3  img_green_std_date3  img_blue_std_date3  \\\n",
       "0               55.745311            47.576383           42.723218   \n",
       "1               42.130924            38.138137           35.142246   \n",
       "2               58.434034            48.106798           43.902810   \n",
       "3               51.046935            44.444291           40.558345   \n",
       "4               32.054249            40.833531           48.325621   \n",
       "...                   ...                  ...                 ...   \n",
       "296141          22.149322            21.775425           21.220923   \n",
       "296142          36.244103            44.609578           49.829084   \n",
       "296143          16.453913            13.275921           11.146906   \n",
       "296144          29.719189            26.584532           22.268071   \n",
       "296145          29.863493            26.546770           22.657286   \n",
       "\n",
       "        img_red_std_date4  img_green_std_date4  img_blue_std_date4  \\\n",
       "0               39.819949            30.864230           28.189604   \n",
       "1               37.129531            28.089549           25.901238   \n",
       "2               42.510625            33.189102           30.522871   \n",
       "3               39.111827            30.762028           28.337671   \n",
       "4               27.578335            28.158172           27.306766   \n",
       "...                   ...                  ...                 ...   \n",
       "296141          31.735119            27.878950           22.753705   \n",
       "296142          52.820758            56.492413           58.892309   \n",
       "296143          13.538151            11.347441           11.297618   \n",
       "296144          23.167710            22.728428           22.132447   \n",
       "296145          19.702818            18.111208           17.132445   \n",
       "\n",
       "        img_red_std_date5  img_green_std_date5  img_blue_std_date5  \n",
       "0               33.813160            33.064014           34.818012  \n",
       "1               30.670052            33.258905           36.139281  \n",
       "2               34.436045            33.546000           35.545531  \n",
       "3               31.285068            32.613142           36.080342  \n",
       "4               40.627077            37.989182           37.177376  \n",
       "...                   ...                  ...                 ...  \n",
       "296141          39.430303            31.233005           32.695174  \n",
       "296142          57.208272            55.111372           57.120977  \n",
       "296143          27.654293            26.528809           25.034740  \n",
       "296144          58.078044            54.960466           53.635703  \n",
       "296145          47.110624            42.584237           46.635505  \n",
       "\n",
       "[296146 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df = pd.DataFrame()\n",
    "                      \n",
    "date_columns = ['date0','date1', 'date2', 'date3', 'date4' ]\n",
    "change_status_columns=['change_status_date0','change_status_date1', 'change_status_date2', 'change_status_date3', 'change_status_date4' ]\n",
    "mean_color_columns = [col for col in train_df.columns if '_mean_date' in col ]\n",
    "std_color_columns = [col for col in train_df.columns if '_std_date' in col]\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "date_format = \"%d-%m-%Y\"\n",
    "train_df[date_columns] = train_df[date_columns].apply(lambda x: pd.to_datetime(x, format=date_format))\n",
    "\n",
    "date_status_dft = pd.DataFrame()\n",
    "dft=train_df[date_columns+change_status_columns+mean_color_columns+std_color_columns]\n",
    "\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date0', 'date1', 'date2', 'date3', 'date4', 'change_status_date0',\n",
      "       'change_status_date1', 'change_status_date2', 'change_status_date3',\n",
      "       'change_status_date4', 'img_red_mean_date1', 'img_green_mean_date1',\n",
      "       'img_blue_mean_date1', 'img_red_mean_date2', 'img_green_mean_date2',\n",
      "       'img_blue_mean_date2', 'img_red_mean_date3', 'img_green_mean_date3',\n",
      "       'img_blue_mean_date3', 'img_red_mean_date4', 'img_green_mean_date4',\n",
      "       'img_blue_mean_date4', 'img_red_mean_date5', 'img_green_mean_date5',\n",
      "       'img_blue_mean_date5', 'img_red_std_date1', 'img_green_std_date1',\n",
      "       'img_blue_std_date1', 'img_red_std_date2', 'img_green_std_date2',\n",
      "       'img_blue_std_date2', 'img_red_std_date3', 'img_green_std_date3',\n",
      "       'img_blue_std_date3', 'img_red_std_date4', 'img_green_std_date4',\n",
      "       'img_blue_std_date4', 'img_red_std_date5', 'img_green_std_date5',\n",
      "       'img_blue_std_date5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "date_df = pd.DataFrame()\n",
    "                      \n",
    "date_columns = ['date0','date1', 'date2', 'date3', 'date4' ]\n",
    "change_status_columns=['change_status_date0','change_status_date1', 'change_status_date2', 'change_status_date3', 'change_status_date4' ]\n",
    "mean_color_columns = [col for col in test_df.columns if '_mean_date' in col ]\n",
    "std_color_columns = [col for col in test_df.columns if '_std_date' in col]\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "date_format = \"%d-%m-%Y\"\n",
    "test_df[date_columns] = test_df[date_columns].apply(lambda x: pd.to_datetime(x, format=date_format, errors='coerce'))\n",
    "\n",
    "date_status_df = pd.DataFrame()\n",
    "df=test_df[date_columns+change_status_columns+mean_color_columns+std_color_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(date_columns)):\n",
    "    date_col = dft.columns[i]\n",
    "    \n",
    "    status_col = dft.columns[i + 5]\n",
    "    mean_red_col='img_red_mean_date'+str(i+1)\n",
    "    mean_blue_col='img_blue_mean_date'+str(i+1)\n",
    "    mean_green_col='img_green_mean_date'+str(i+1)\n",
    "    std_red_col='img_red_std_date'+str(i+1)\n",
    "    std_blue_col='img_blue_std_date'+str(i+1)\n",
    "    std_green_col='img_green_std_date'+str(i+1)\n",
    "\n",
    "    date_status_dft[f'date_status_{i}'] = tuple(zip(dft[date_col].dt.date, dft[status_col],dft[mean_red_col],dft[mean_blue_col],dft[mean_green_col],dft[std_red_col],dft[std_blue_col],dft[std_green_col]))\n",
    "def custom_sort(row):\n",
    "    return sorted(row, key=lambda x: (x[0] if not pd.isna(x[0]) else pd.Timestamp.max.date(),))\n",
    "\n",
    "date_status_dft[date_status_dft.columns] = date_status_dft[date_status_dft.columns].apply(custom_sort, axis=1, result_type='expand')\n",
    "\n",
    "for i, date_col in enumerate(date_columns):\n",
    "    date_status_dft[f'{date_col}'] = date_status_dft[f'date_status_{i}'].str[0]\n",
    "    date_status_dft[f'change_status_{date_col}'] = date_status_dft[f'date_status_{i}'].str[1]\n",
    "    date_status_dft[f'img_red_mean_{date_col}'] = date_status_dft[f'date_status_{i}'].str[2]\n",
    "    date_status_dft[f'img_blue_mean_{date_col}'] = date_status_dft[f'date_status_{i}'].str[3]\n",
    "    date_status_dft[f'img_green_mean_{date_col}'] = date_status_dft[f'date_status_{i}'].str[4]\n",
    "    date_status_dft[f'img_red_std_{date_col}'] = date_status_dft[f'date_status_{i}'].str[5]\n",
    "    date_status_dft[f'img_blue_std_{date_col}'] = date_status_dft[f'date_status_{i}'].str[6]\n",
    "    date_status_dft[f'img_green_std_{date_col}'] = date_status_dft[f'date_status_{i}'].str[7]\n",
    "date_status_dft = date_status_dft.drop(columns=[f'date_status_{i}' for i in range(len(date_columns))])\n",
    "\n",
    "train_df.drop(date_columns,axis=1,inplace=True)\n",
    "train_df.drop(change_status_columns,axis=1,inplace=True)\n",
    "train_df.drop(mean_color_columns,axis=1,inplace=True)\n",
    "train_df.drop(std_color_columns,axis=1,inplace=True)\n",
    "train_df=pd.concat([train_df,date_status_dft],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(date_columns)):\n",
    "    date_col = df.columns[i]\n",
    "    \n",
    "    status_col = df.columns[i + 5]\n",
    "    mean_red_col='img_red_mean_date'+str(i+1)\n",
    "    mean_blue_col='img_blue_mean_date'+str(i+1)\n",
    "    mean_green_col='img_green_mean_date'+str(i+1)\n",
    "    std_red_col='img_red_std_date'+str(i+1)\n",
    "    std_blue_col='img_blue_std_date'+str(i+1)\n",
    "    std_green_col='img_green_std_date'+str(i+1)\n",
    "\n",
    "    date_status_df[f'date_status_{i}'] = tuple(zip(df[date_col].dt.date, df[status_col],df[mean_red_col],df[mean_blue_col],df[mean_green_col],df[std_red_col],df[std_blue_col],df[std_green_col]))\n",
    "\n",
    "def custom_sort(row):\n",
    "    return sorted(row, key=lambda x: (x[0] if not pd.isna(x[0]) else pd.Timestamp.max.date(),))\n",
    "\n",
    "\n",
    "date_status_df[date_status_df.columns] = date_status_df[date_status_df.columns].apply(custom_sort, axis=1, result_type='expand')\n",
    "\n",
    "for i, date_col in enumerate(date_columns):\n",
    "    date_status_df[f'{date_col}'] = date_status_df[f'date_status_{i}'].str[0]\n",
    "    date_status_df[f'change_status_{date_col}'] = date_status_df[f'date_status_{i}'].str[1]\n",
    "    date_status_df[f'img_red_mean_{date_col}'] = date_status_df[f'date_status_{i}'].str[2]\n",
    "    date_status_df[f'img_blue_mean_{date_col}'] = date_status_df[f'date_status_{i}'].str[3]\n",
    "    date_status_df[f'img_green_mean_{date_col}'] = date_status_df[f'date_status_{i}'].str[4]\n",
    "    date_status_df[f'img_red_std_{date_col}'] = date_status_df[f'date_status_{i}'].str[5]\n",
    "    date_status_df[f'img_blue_std_{date_col}'] = date_status_df[f'date_status_{i}'].str[6]\n",
    "    date_status_df[f'img_green_std_{date_col}'] = date_status_df[f'date_status_{i}'].str[7]\n",
    "date_status_df = date_status_df.drop(columns=[f'date_status_{i}' for i in range(len(date_columns))])\n",
    "\n",
    "test_df.drop(date_columns,axis=1,inplace=True)\n",
    "test_df.drop(change_status_columns,axis=1,inplace=True)\n",
    "test_df.drop(mean_color_columns,axis=1,inplace=True)\n",
    "test_df.drop(std_color_columns,axis=1,inplace=True)\n",
    "test_df=pd.concat([test_df,date_status_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating new temporal features\n",
    "\n",
    "We start by introducing the number of days between two consecutive dates, acknowledging the\n",
    "construction pace variability across different geographic zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dft = pd.DataFrame()\n",
    "                      \n",
    "\n",
    "for i in range(len(date_columns)-1):\n",
    "    try:\n",
    "        date_dft[f'days_between_{i}_{i+1}'] = ((pd.to_datetime(train_df[date_columns[i+1]], format=date_format, errors='coerce') - pd.to_datetime(train_df[date_columns[i]], format=date_format, errors='coerce')).dt.days )/365\n",
    "    except:\n",
    "        date_dft[f'days_between_{i}_{i+1}']=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(date_columns)-1):\n",
    "    try:\n",
    "        date_df[f'days_between_{i}_{i+1}'] = ((pd.to_datetime(test_df[date_columns[i+1]], format=date_format, errors='coerce') - pd.to_datetime(test_df[date_columns[i]], format=date_format, errors='coerce')).dt.days) /365\n",
    "    except:\n",
    "        date_df[f'days_between_{i}_{i+1}']=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also computed the difference between ’date0’ and a reference date for each datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ref = pd.to_datetime(pd.Series(['01-01-2000'] * len(train_df)), format='%d-%m-%Y')\n",
    "try:\n",
    "    train_df['t0'] = (pd.to_datetime(train_df['date0'],format=date_format,errors='coerce')- date_ref).dt.days/365\n",
    "except:\n",
    "    train_df['t0']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14.194521\n",
       "1    14.194521\n",
       "2    14.194521\n",
       "3    14.194521\n",
       "4    14.194521\n",
       "5    14.194521\n",
       "6    14.194521\n",
       "7    14.194521\n",
       "8    14.194521\n",
       "9    14.194521\n",
       "Name: t0, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_ref = pd.to_datetime(pd.Series(['01-01-2000'] * len(train_df)), format='%d-%m-%Y')\n",
    "try:\n",
    "    test_df['t0'] = (pd.to_datetime(test_df['date0'],format=date_format,errors='coerce')- date_ref).dt.days/365\n",
    "\n",
    "except:\n",
    "    test_df['t0'] =None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, we decided to drop the dates columns as they no longer retained significance for\n",
    "our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    train_df.drop('date'+str(i),axis=1,inplace=True)\n",
    "train_df=pd.concat([train_df,date_dft],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    test_df.drop('date'+str(i),axis=1,inplace=True)\n",
    "test_df=pd.concat([test_df,date_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Introducing geometric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import Polygon , MultiPolygon\n",
    "from shapely.wkt import loads\n",
    "\n",
    "# Function to calculate the geometric features\n",
    "\n",
    "def calculate_geometry(geometry):    \n",
    "    polygon = loads(geometry)  \n",
    "    try:\n",
    "        area = polygon.area\n",
    "        perimeter = polygon.length\n",
    "        num_edges = len(polygon.exterior.coords) - 1  \n",
    "        longest_diagonal = LineString(MultiPolygon([polygon]).minimum_rotated_rectangle.exterior.coords)\n",
    "        shortest_diagonal = LineString(MultiPolygon([polygon]).convex_hull.exterior.coords)\n",
    "        aspect_ratio = longest_diagonal.length / shortest_diagonal.length\n",
    "        ratioAP=area/perimeter**2\n",
    "        min_x, min_y, max_x, max_y = polygon.bounds\n",
    "        width = max_x - min_x\n",
    "        height = max_y - min_y\n",
    "    except:\n",
    "        area = None\n",
    "        perimeter = None\n",
    "        num_edges = None\n",
    "        aspect_ratio=None\n",
    "        ratioAP=None\n",
    "        width=None\n",
    "        height=None\n",
    "    return area, perimeter, num_edges,aspect_ratio,ratioAP,width,height\n",
    "\n",
    "# Apply the function to 'geometry' column to create area column, perimeter column, etc\n",
    "train_df[['area','perimeter','edges','aspect_ratio','ratioAP','width','height']] = train_df['geometry'].apply(lambda x: pd.Series(calculate_geometry(x)))\n",
    "test_df[['area','perimeter','edges','aspect_ratio','ratioAP','width','height']] = test_df['geometry'].apply(lambda x: pd.Series(calculate_geometry(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discarding geometry column\n",
    "train_df.drop('geometry',axis=1,inplace=True)\n",
    "test_df.drop('geometry',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting change status columns from strings to numerical values using Label Encoding\n",
    "\n",
    "We ordered the change status values in a coherent way, so the label encoding holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "changestatus_values = ['Land Cleared','Greenland','Excavation','Materials Introduced'  ,'Materials Dumped','Prior Construction','Construction Started','Construction Midway','Construction Done','Operational']\n",
    "encoding_change_status_order={}\n",
    "for i in range(len(changestatus_values)): \n",
    "    encoding_change_status_order[changestatus_values[i]]=i\n",
    "\n",
    "for i in range(5):\n",
    "    train_df['change_status_date'+str(i)]=train_df['change_status_date'+str(i)].map(encoding_change_status_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "changestatus_values = ['Land Cleared','Greenland','Excavation','Materials Introduced'  ,'Materials Dumped','Prior Construction','Construction Started','Construction Midway','Construction Done','Operational']\n",
    "encoding_change_status_order={}\n",
    "for i in range(len(changestatus_values)): \n",
    "    encoding_change_status_order[changestatus_values[i]]=i\n",
    "\n",
    "for i in range(5):\n",
    "    test_df['change_status_date'+str(i)]=test_df['change_status_date'+str(i)].map(encoding_change_status_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geography_type_Barren Land', 'geography_type_Coastal',\n",
       "       'geography_type_Dense Forest', 'geography_type_Desert',\n",
       "       'geography_type_Farms', 'geography_type_Grass Land',\n",
       "       'geography_type_Hills', 'geography_type_Lakes', 'geography_type_River',\n",
       "       'geography_type_Snow', 'geography_type_Sparse Forest',\n",
       "       'urban_type_Dense Urban', 'urban_type_Industrial', 'urban_type_Rural',\n",
       "       'urban_type_Sparse Urban', 'urban_type_Urban Slum',\n",
       "       'change_status_date0', 'img_red_mean_date0', 'img_blue_mean_date0',\n",
       "       'img_green_mean_date0', 'img_red_std_date0', 'img_blue_std_date0',\n",
       "       'img_green_std_date0', 'change_status_date1', 'img_red_mean_date1',\n",
       "       'img_blue_mean_date1', 'img_green_mean_date1', 'img_red_std_date1',\n",
       "       'img_blue_std_date1', 'img_green_std_date1', 'change_status_date2',\n",
       "       'img_red_mean_date2', 'img_blue_mean_date2', 'img_green_mean_date2',\n",
       "       'img_red_std_date2', 'img_blue_std_date2', 'img_green_std_date2',\n",
       "       'change_status_date3', 'img_red_mean_date3', 'img_blue_mean_date3',\n",
       "       'img_green_mean_date3', 'img_red_std_date3', 'img_blue_std_date3',\n",
       "       'img_green_std_date3', 'change_status_date4', 'img_red_mean_date4',\n",
       "       'img_blue_mean_date4', 'img_green_mean_date4', 'img_red_std_date4',\n",
       "       'img_blue_std_date4', 'img_green_std_date4', 't0', 'days_between_0_1',\n",
       "       'days_between_1_2', 'days_between_2_3', 'days_between_3_4', 'area',\n",
       "       'perimeter', 'edges', 'aspect_ratio', 'ratioAP', 'ratioPW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping index column since it is of no use.\n",
    "\n",
    "train_df.drop('index',axis=1,inplace=True)\n",
    "test_df.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "       'Mega Projects': 5}\n",
    "\n",
    "y = train_df['change_type'].apply(lambda x: change_type_map[x])\n",
    "\n",
    "train_df.drop('change_type',inplace=True,axis=1)\n",
    "X=train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling missing values by imputing the corresponding mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_train = X.mean()\n",
    "X = train_df.fillna(means_train)\n",
    "test_df = test_df.fillna(means_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Model tuning and Comparison\n",
    "\n",
    "- ### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X, y)\n",
    "\n",
    "predictions = knn.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions, columns=['change_type'])\n",
    "pred_df.to_csv(\"KNN_submissions.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf_classifier = RandomForestClassifier(n_estimators=205,random_state=42,max_depth=45)\n",
    "rf_classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_df\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "pred_df = pd.DataFrame(y_pred, columns=['change_type'])\n",
    "pred_df.to_csv(\"random_forest_submissions.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_classifier = XGBClassifier(n_estimators=4500,learning_rate=0.1)\n",
    "xgb_classifier.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_df\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "pred_df = pd.DataFrame(y_pred, columns=['change_type'])\n",
    "pred_df.to_csv(\"XGB_submissions.csv\", index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation using f1_macro and accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.54171872 0.62077698 0.53274578 0.60747269 0.63727228]\n",
      "Mean F1 Score: 0.5879972928169523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(xgb_classifier,X, y, cv=5,scoring='f1_macro') \n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "mean_score = scores.mean()\n",
    "print(\"Mean F1 Score:\", mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = cross_val_score(xgb_classifier,X, y, cv=5,scoring='accuracy') \n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "mean_score2 = scores2.mean()\n",
    "print(\"Accuracy Score:\", mean_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(test_df)\n",
    "\n",
    "# Initialize the Logistic Regression model with regularization and increased max_iter\n",
    "logreg_model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=2000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train_scaled, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(logreg_model,X, y, cv=5,scoring='accuracy')\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "mean_score = scores.mean()\n",
    "print(\"Mean accuracy:\", mean_score)\n",
    "scores2 = cross_val_score(logreg_model,X, y, cv=5,scoring='f1_macro')\n",
    "print(\"Cross-Validation Scores:\", scores2)\n",
    "mean_score2 = scores2.mean()\n",
    "print(\"Mean F1 Score:\", mean_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_model.predict(X_test_scaled)\n",
    "pred_df = pd.DataFrame(y_pred, columns=['change_type'])\n",
    "pred_df.to_csv(\"logreg_sumbmissions.csv\", index=True, index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
